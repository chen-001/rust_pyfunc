[
  {
    "name": "PriceTree",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "PriceTreeViz",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "RollingFutureAccessor",
    "description": "<p>用于在pandas DataFrame或Series上实现向后滚动窗口计算的访问器。</p>\n<h2>支持的统计量类型：</h2>\n<ul>\n<li>mean: 计算后面窗口内的均值</li>\n<li>sum: 计算后面窗口内的总和</li>\n<li>max: 计算后面窗口内的最大值</li>\n<li>min: 计算后面窗口内的最小值</li>\n<li>std: 计算后面窗口内的标准差</li>\n<li>median: 计算后面窗口内的中位数</li>\n<li>count: 计算后面窗口内的数据点数量</li>\n<li>rank: 计算当前值在后面窗口内的分位数（0到1之间）</li>\n<li>skew: 计算后面窗口的偏度</li>\n<li>trend_time: 计算后面窗口内数据序列与时间序列的相关系数</li>\n<li>trend_oneton: 计算后面窗口内数据序列与1到n序列的相关系数（忽略时间间隔）</li>\n<li>last: 计算后面窗口内的最后一个值</li>\n</ul>\n<p>注意：所有计算都不包括当前时间点的值，只考虑后面窗口内的值</p>\n<h2>使用方法：</h2>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>import pandas as pd\nfrom rust_pyfunc import rolling_future</p>\n<h1>DataFrame示例</h1>\n<p>df = pd.DataFrame({\n...     'time': pd.date_range('2024-01-01', periods=5, freq='s'),\n...     'value': [1, 2, 3, 4, 5]\n... })\ndf.set_index('time', inplace=True)\ndf.rolling_future('2s').mean()  # 计算每个时间点之后2秒内的均值\ndf.rolling_future('2s').rank()  # 计算每个值在后面2秒内的分位数</p>\n<h1>Series示例</h1>\n<p>s = pd.Series([1, 2, 3, 4, 5], \n...               index=pd.date_range('2024-01-01', periods=5, freq='s'))\ns.rolling_future('2s').mean()  # 计算每个时间点之后2秒内的均值\ns.rolling_future('2s').trend_time()  # 计算后面2秒内的趋势</p>\n</blockquote>\n</blockquote>\n</blockquote>",
    "params": []
  },
  {
    "name": "RollingPastAccessor",
    "description": "<p>用于在pandas DataFrame或Series上实现向前滚动窗口计算的访问器。</p>\n<h2>支持的统计量类型：</h2>\n<ul>\n<li>mean: 计算前面窗口内的均值</li>\n<li>sum: 计算前面窗口内的总和</li>\n<li>max: 计算前面窗口内的最大值</li>\n<li>min: 计算前面窗口内的最小值</li>\n<li>std: 计算前面窗口内的标准差</li>\n<li>median: 计算前面窗口内的中位数</li>\n<li>count: 计算前面窗口内的数据点数量</li>\n<li>rank: 计算当前值在前面窗口内的分位数（0到1之间）</li>\n<li>skew: 计算前面窗口的偏度</li>\n<li>trend_time: 计算前面窗口内数据序列与时间序列的相关系数</li>\n<li>trend_oneton: 计算前面窗口内数据序列与1到n序列的相关系数（忽略时间间隔）</li>\n<li>first: 计算前面窗口内的第一个值</li>\n<li>last: 计算前面窗口内的最后一个值</li>\n</ul>\n<p>注意：所有计算都可以选择是否包括当前时间点的值</p>\n<h2>使用方法：</h2>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>import pandas as pd\nfrom rust_pyfunc import rolling_past</p>\n<h1>DataFrame示例</h1>\n<p>df = pd.DataFrame({\n...     'time': pd.date_range('2024-01-01', periods=5, freq='s'),\n...     'value': [1, 2, 3, 4, 5]\n... })\ndf.set_index('time', inplace=True)\ndf.rolling_past('2s').mean()  # 计算每个时间点之前2秒内的均值\ndf.rolling_past('2s').first()  # 计算每个时间点之前2秒内的第一个值</p>\n<h1>Series示例</h1>\n<p>s = pd.Series([1, 2, 3, 4, 5], \n...               index=pd.date_range('2024-01-01', periods=5, freq='s'))\ns.rolling_past('2s').mean()  # 计算每个时间点之前2秒内的均值\ns.rolling_past('2s').trend_time()  # 计算前面2秒内的趋势</p>\n</blockquote>\n</blockquote>\n</blockquote>",
    "params": []
  },
  {
    "name": "analyze_asks",
    "description": "<p>异常挂单区间特征提取器</p>\n<p>输入</p>",
    "params": [
      "exchtime",
      "number",
      "price",
      "volume",
      "volume_percentile",
      "min_duration"
    ]
  },
  {
    "name": "analyze_long_orders",
    "description": "<p>分析漫长订单并计算比值</p>\n<p>参数:\n- exchtime: 交易时间数组(纳秒)\n- order: 订单编号数组\n- volume: 成交量数组\n- top_ratio: 可选参数，表示只计算最漫长的一部分订单的比例(0.0-1.0)\n             默认为1.0表示计算所有订单，0.5表示只计算最漫长的一半订单</p>\n<p>返回: (时间漫长比值序列, 次数漫长比值序列, 两者都漫长比值序列,\n      时间漫长总比值, 次数漫长总比值, 两者都漫长总比值)</p>",
    "params": []
  },
  {
    "name": "analyze_long_orders_python",
    "description": "<p>Python版本的漫长订单分析(用于测试对比)</p>",
    "params": []
  },
  {
    "name": "analyze_retreat_advance",
    "description": "<p>分析股票交易中的\"以退为进\"现象</p>\n<p>该函数分析当价格触及某个局部高点后回落，然后在该价格的异常大挂单量消失后\n成功突破该价格的现象。</p>",
    "params": [
      "trade_times",
      "trade_prices",
      "trade_volumes",
      "trade_flags",
      "orderbook_times",
      "orderbook_prices",
      "orderbook_volumes",
      "volume_percentile",
      "time_window_minutes"
    ]
  },
  {
    "name": "analyze_retreat_advance_v2",
    "description": "<p>分析股票交易中的\"以退为进\"现象（纳秒版本）</p>\n<p>该函数分析当价格触及某个局部高点后回落，然后在该价格的异常大挂单量消失后\n成功突破该价格的现象。该版本包含局部高点去重功能，避免在同一价格水平的\n连续成交中重复识别相同的\"以退为进\"过程。</p>",
    "params": [
      "trade_times",
      "trade_prices",
      "trade_volumes",
      "trade_flags",
      "orderbook_times",
      "orderbook_prices",
      "orderbook_volumes",
      "volume_percentile",
      "time_window_minutes",
      "breakthrough_threshold",
      "dedup_time_seconds",
      "find_local_lows",
      "interval_mode"
    ]
  },
  {
    "name": "analyze_sequence_permutations_v0816_fixed",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "batch_factor_neutralization_io_optimized",
    "description": "<p>I/O优化的批量因子中性化函数</p>",
    "params": []
  },
  {
    "name": "brachistochrone_curve",
    "description": "<p>计算最速曲线（投掷线）并返回x_series对应的y坐标</p>",
    "params": [
      "x1",
      "y1",
      "x2",
      "y2",
      "x_series",
      "timeout_seconds"
    ]
  },
  {
    "name": "brachistochrone_curve_v2",
    "description": "<p>修正版最速曲线函数，确保终点严格一致  </p>\n<p>此函数解决了原版brachistochrone_curve终点不一致的问题\n通过强制约束终点坐标，确保数学正确性</p>",
    "params": [
      "x1",
      "y1",
      "x2",
      "y2",
      "x_series",
      "timeout_seconds"
    ]
  },
  {
    "name": "calculate_base_entropy",
    "description": "<p>计算基准熵 - 基于到当前时间点为止的订单分布计算香农熵</p>\n<p>参数:\n* exchtime: 交易时间数组（纳秒时间戳）\n* order: 订单号数组\n* volume: 成交量数组\n* index: 计算熵值的当前索引位置</p>\n<p>返回:\n* 基准熵值</p>",
    "params": []
  },
  {
    "name": "calculate_binned_entropy_1d",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "calculate_binned_entropy_2d",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "calculate_entropy_1d",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "calculate_entropy_2d",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "calculate_entropy_discrete_1d",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "calculate_entropy_discrete_2d",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "calculate_large_order_nearby_small_order_time_gap",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "calculate_lyapunov_exponent",
    "description": "<p>统一的Lyapunov指数计算函数</p>",
    "params": []
  },
  {
    "name": "calculate_order_time_gap_and_price_percentile_ultra_sorted",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "calculate_order_time_gap_and_price_percentile_ultra_sorted_v2",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "calculate_shannon_entropy_change",
    "description": "<p>计算价格变化后的香农熵变</p>",
    "params": [
      "exchtime",
      "order",
      "volume",
      "price",
      "window_seconds",
      "top_k"
    ]
  },
  {
    "name": "calculate_shannon_entropy_change_at_low",
    "description": "<p>在价格创新低时计算香农熵变</p>\n<p>参数:\n* exchtime: 交易时间数组\n* order: 订单号数组\n* volume: 成交量数组\n* price: 价格数组\n* window_seconds: 时间窗口大小（秒）\n* bottom_k: 如果提供，则只计算价格最低的k个点的熵变，默认为None（计算所有价格创新低点）</p>\n<p>返回:\n* 香农熵变数组，只在价格创新低时有值，其他位置为NaN</p>",
    "params": []
  },
  {
    "name": "calculate_trade_time_gap_and_price_percentile_ultra_sorted",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "calculate_window_entropy",
    "description": "<p>计算窗口熵 - 基于从当前时间点到未来指定时间窗口内的订单分布计算香农熵</p>\n<p>参数:\n* exchtime: 交易时间数组（纳秒时间戳）\n* order: 订单号数组\n* volume: 成交量数组\n* index: 计算熵值的当前索引位置\n* window_seconds: 向前查看的时间窗口大小，单位为秒</p>\n<p>返回:\n* 窗口熵值</p>",
    "params": []
  },
  {
    "name": "check_string_proximity",
    "description": "<p>计算两个字符串的接近度（最少操作次数）</p>",
    "params": [
      "word1",
      "word2"
    ]
  },
  {
    "name": "check_string_proximity_matrix",
    "description": "<p>计算字符串数组中所有字符串对之间的接近度矩阵</p>",
    "params": [
      "words"
    ]
  },
  {
    "name": "check_string_proximity_matrix_with_tolerance",
    "description": "<p>计算字符串数组中所有字符串对之间的接近度矩阵，支持宽限参数</p>",
    "params": [
      "words",
      "tolerance"
    ]
  },
  {
    "name": "check_string_proximity_with_tolerance",
    "description": "<p>计算两个字符串的接近度（最少操作次数），支持宽限参数</p>",
    "params": [
      "word1",
      "word2",
      "tolerance"
    ]
  },
  {
    "name": "column_correlation_batch",
    "description": "<p>批量计算多列相关系数的优化版本</p>\n<p>为了进一步提升性能，使用批量处理和更好的缓存局部性</p>",
    "params": []
  },
  {
    "name": "column_correlation_fast",
    "description": "<p>快速计算两个二维数组对应列的相关系数</p>\n<p>使用高度优化的算法计算两个n×n数组对应列之间的皮尔逊相关系数。\n采用Welford's online算法确保数值稳定性，优化内存访问模式以提升性能。</p>",
    "params": [
      "array1",
      "array2"
    ]
  },
  {
    "name": "compute_max_eigenvalue",
    "description": "<p>计算二维方阵的最大特征值和对应的特征向量\n使用幂迭代法计算，不使用并行计算</p>",
    "params": [
      "matrix"
    ]
  },
  {
    "name": "compute_non_breakthrough_stats",
    "description": "<p>计算股票逐笔成交数据中\"价格未突破上一分钟价格范围\"的24个统计指标</p>\n<p>参数:\nexchtime: 成交时间(纳秒)\nvolume: 成交量(支持浮点数)\nprice: 成交价格\nflag: 主动买卖标识(66=主买, 83=主卖)</p>\n<p>返回:\n(n×24的二维数组, 24个中文列名)</p>",
    "params": []
  },
  {
    "name": "compute_price_cycle_features_b_segments_enhanced",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "corrwith",
    "description": "<p>计算两个DataFrame对应列或行之间的相关系数。</p>\n<p>这个函数是pandas的corrwith方法的Rust实现包装，用于计算两个DataFrame中对应列（或行）\n之间的皮尔逊相关系数。会自动处理两个DataFrame的列名（或行名）匹配情况。</p>",
    "params": [
      "df1",
      "df2",
      "axis",
      "use_single_thread"
    ]
  },
  {
    "name": "cosine_similarity_matrix",
    "description": "<p>精简版余弦相似度矩阵计算（只返回余弦相似度矩阵）</p>\n<p>主要优化技术：\n- 零拷贝输入：使用PyReadonlyArray1避免Python到Rust的数据拷贝\n- SIMD向量化：使用AVX2指令集并行计算4个元素\n- 对称性优化：只计算上三角矩阵，减少一半计算量\n- 直接内存操作：直接写入numpy数组内存，避免中间分配\n- 缓存友好：优化内存访问模式，提高缓存命中率\n- 内存优化：只返回一个矩阵，减少50%内存使用</p>",
    "params": []
  },
  {
    "name": "dataframe_corrwith",
    "description": "<p>计算两个数据框对应列的相关系数。</p>\n<p>这个函数类似于pandas中的df.corrwith(df1)，计算两个数据框中对应列之间的皮尔逊相关系数。\n相关系数范围为[-1, 1]，其中：\n- 1表示完全正相关\n- -1表示完全负相关\n- 0表示无相关性</p>",
    "params": [
      "df1",
      "df2",
      "axis"
    ]
  },
  {
    "name": "dataframe_corrwith_single_thread",
    "description": "<p>计算两个数据框对应列的相关系数（单线程版本）。</p>\n<p>这个函数是 dataframe_corrwith 的单线程版本，在处理小规模数据或内存受限环境时提供更好的性能。\n计算两个数据框中对应列之间的皮尔逊相关系数，不使用多线程并行处理。</p>",
    "params": [
      "df1",
      "df2",
      "axis",
      "drop_na"
    ]
  },
  {
    "name": "difference_matrix",
    "description": "<p>高性能计算差值矩阵 (SIMD优化版本)</p>\n<p>输入一个一维数组，返回一个二维数组，其中第i行第j列的元素是输入数组第i个元素和第j个元素的差值</p>\n<p>优化策略:\n1. 使用AVX2 SIMD指令集加速向量化计算 (一次处理4个f64)\n2. 优化内存访问模式提升缓存命中率\n3. 循环展开减少分支预测失败\n4. 内存预分配减少动态分配开销</p>\n<h1>Arguments</h1>\n<ul>\n<li><code>data</code> - 输入的一维数组 (numpy array)</li>\n</ul>\n<h1>Returns</h1>\n<ul>\n<li><code>PyResult&lt;&amp;PyArray2&lt;f64&gt;&gt;</code> - 返回的差值矩阵</li>\n</ul>",
    "params": []
  },
  {
    "name": "difference_matrix_memory_efficient",
    "description": "<p>内存高效版本的差值矩阵计算 (针对超大矩阵优化)</p>\n<p>使用分块计算策略提高缓存利用率，减少内存带宽瓶颈</p>",
    "params": []
  },
  {
    "name": "distances_to_frontier",
    "description": "<p>计算收益序列中每个聚合块到马科维茨有效前沿的距离</p>\n<h1>功能说明</h1>\n<ol>\n<li>将输入收益序列按指定大小分块聚合</li>\n<li>计算块间样本协方差矩阵（带岭化保证正定性）</li>\n<li>构造马科维茨无约束有效前沿</li>\n<li>使用KKT-λ四次方程法计算每个资产点到前沿的最短距离</li>\n</ol>\n<h1>参数</h1>\n<ul>\n<li><code>r</code> - 1D float64数组，单日3秒频率收益序列</li>\n<li><code>group_size</code> - 每多少行聚合成一块（x）</li>\n<li><code>drop_last</code> - 尾部不足group_size行时是否丢弃，默认true</li>\n<li><code>ddof</code> - 协方差/方差的自由度调整，默认1（样本协方差）</li>\n<li><code>ridge</code> - 岭化强度系数，默认1e-6</li>\n<li><code>timestamps</code> - 可选的int64时间戳数组（与<code>r</code>等长），用于标记每个聚合块的首个时间点</li>\n</ul>\n<h1>返回值</h1>\n<p>包含两个1D数组的元组：(block_timestamps, distances)，长度均为m\n- block_timestamps：每个聚合块的首个时间戳（若未提供timestamps，则返回0..m-1的序列）\n- distances：对应资产点到有效前沿的距离</p>\n<h1>数值提示</h1>\n<p>当 m &gt;&gt; group_size 时，协方差矩阵可能秩亏，需要通过增大ridge参数保证可逆性</p>\n<h1>示例</h1>\n<p>```python\nimport numpy as np\nfrom rust_pyfunc import distances_to_frontier</p>\n<h1>生成测试数据</h1>\n<p>np.random.seed(0)\nr = 1e-4 * np.random.randn(4800).astype(np.float64)</p>\n<h1>每1分钟聚合（20个3秒间隔）</h1>\n<p>block_ts, distances = distances_to_frontier(r, group_size=20)\nprint(distances.shape)  # (240,)\n```</p>",
    "params": []
  },
  {
    "name": "dtw_distance",
    "description": "<p>DTW（动态时间规整）是一种测量两个时间序列相似度的方法。\n该算法计算两个可能长度不同、tempo不同的时间序列间的最优匹配。</p>",
    "params": [
      "s1",
      "s2",
      "radius",
      "timeout_seconds"
    ]
  },
  {
    "name": "factor_correlation_by_date",
    "description": "<p>按日期计算ret和fac的分组相关系数</p>\n<h1>Arguments</h1>\n<ul>\n<li><code>dates</code> - 日期时间戳数组</li>\n<li><code>ret</code> - 收益率数组</li>\n<li><code>fac</code> - 因子值数组</li>\n</ul>\n<h1>Returns</h1>\n<ul>\n<li>(unique_dates, full_corr, low_corr, high_corr) - 四个数组</li>\n<li>unique_dates: 唯一日期</li>\n<li>full_corr: 每日全体数据的ret和fac排序值相关系数</li>\n<li>low_corr: 每日fac小于中位数部分的ret和fac排序值相关系数</li>\n<li>high_corr: 每日fac大于中位数部分的ret和fac排序值相关系数</li>\n</ul>",
    "params": []
  },
  {
    "name": "factor_grouping",
    "description": "<p>按日期对因子值进行分组</p>\n<h1>Arguments</h1>\n<ul>\n<li><code>dates</code> - 日期时间戳数组</li>\n<li><code>factors</code> - 因子值数组</li>\n<li><code>groups_num</code> - 分组数量，默认为10</li>\n</ul>\n<h1>Returns</h1>\n<ul>\n<li>每个观测值对应的分组号(1到groups_num)</li>\n</ul>",
    "params": []
  },
  {
    "name": "fast_correlation_matrix",
    "description": "<p>快速计算相关性矩阵，类似于pandas的df.corr()功能。\n使用并行计算和优化算法大幅提升计算性能。</p>",
    "params": [
      "data",
      "method",
      "min_periods",
      "max_workers"
    ]
  },
  {
    "name": "fast_correlation_matrix_v2",
    "description": "<p>超快速计算相关性矩阵，进一步优化版本。\n采用SIMD优化和更好的内存访问模式。</p>",
    "params": [
      "data",
      "method",
      "min_periods",
      "max_workers"
    ]
  },
  {
    "name": "fast_correlation_matrix_v2_df",
    "description": "<p>超快速计算DataFrame的相关性矩阵，进一步优化版本</p>\n<p>这是rust_pyfunc.fast_correlation_matrix_v2的DataFrame封装版本，可以直接传入DataFrame\n并返回保持原有列名作为索引和列名的相关性矩阵DataFrame。</p>",
    "params": [
      "df",
      "method",
      "min_periods",
      "max_workers"
    ]
  },
  {
    "name": "fast_correlation_matrix_v2_df",
    "description": "<p>超快速计算DataFrame的相关性矩阵，进一步优化版本</p>\n<p>这是rust_pyfunc.fast_correlation_matrix_v2的DataFrame封装版本，可以直接传入DataFrame\n并返回保持原有列名作为索引和列名的相关性矩阵DataFrame。</p>",
    "params": [
      "df",
      "method",
      "min_periods",
      "max_workers"
    ]
  },
  {
    "name": "fast_correlation_matrix_v2_df",
    "description": "<p>超快速计算DataFrame的相关性矩阵，进一步优化版本</p>\n<p>这是rust_pyfunc.fast_correlation_matrix_v2的DataFrame封装版本，可以直接传入DataFrame\n并返回保持原有列名作为索引和列名的相关性矩阵DataFrame。</p>",
    "params": [
      "df",
      "method",
      "min_periods",
      "max_workers"
    ]
  },
  {
    "name": "fast_dtw_distance",
    "description": "<p>优化版DTW距离函数，使用以下技术提升性能：\n1. 使用一维数组代替二维数组，减少内存分配和间接访问\n2. 提前计算常用值，减少重复计算\n3. 对于窗口计算进行更高效的实现\n4. 优化内存访问模式，提高缓存命中率\n5. 智能初始化窗口内单元格，避免无限值问题\n6. 自动调整radius大小，确保计算结果有效</p>\n<p>```python\nimport numpy as np\nfrom rust_pyfunc import fast_dtw_distance, dtw_distance</p>\n<h1>创建两个时间序列</h1>\n<p>s1 = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\ns2 = np.array([1.1, 2.1, 3.1, 4.1, 5.1])</p>\n<h1>比较两种实现的结果和性能</h1>\n<p>import time</p>\n<p>start = time.time()\nresult1 = dtw_distance(s1, s2)\ntime1 = time.time() - start</p>\n<p>start = time.time()\nresult2 = fast_dtw_distance(s1, s2)\ntime2 = time.time() - start</p>\n<p>print(f\"标准DTW距离: {result1:.6f}, 耗时: {time1:.6f}秒\")\nprint(f\"快速DTW距离: {result2:.6f}, 耗时: {time2:.6f}秒\")\nprint(f\"加速比: {time1/time2:.2f}倍\")\n```</p>",
    "params": []
  },
  {
    "name": "fast_find_half_extreme_time",
    "description": "<p>计算半极端时间的优化版本</p>\n<p>该函数针对find_half_extreme_time进行了多项优化：\n1. 预计算和缓存 - 避免重复计算时间差和比率\n2. 数据布局优化 - 改进内存访问模式\n3. 条件分支优化 - 减少分支预测失败\n4. 界限优化 - 提前确定搜索范围</p>",
    "params": []
  },
  {
    "name": "fast_inner_join_dataframes",
    "description": "<p>高性能DataFrame内连接，专门优化Python DataFrame处理</p>",
    "params": []
  },
  {
    "name": "fast_inner_join_df",
    "description": "<p>快速内连接的便捷函数</p>",
    "params": []
  },
  {
    "name": "fast_left_join_df",
    "description": "<p>快速左连接的便捷函数</p>",
    "params": []
  },
  {
    "name": "fast_merge",
    "description": "<p>高性能merge函数，支持数据表连接操作</p>",
    "params": [
      "left_data",
      "right_data",
      "left_keys",
      "right_keys",
      "how"
    ]
  },
  {
    "name": "fast_merge_df",
    "description": "<p>高性能的DataFrame merge函数</p>\n<p>这是rust_pyfunc.fast_merge的DataFrame封装版本，可以直接传入DataFrame\n并返回标准的DataFrame结果。</p>",
    "params": [
      "left",
      "right",
      "on",
      "left_on",
      "right_on",
      "how"
    ]
  },
  {
    "name": "fast_merge_df",
    "description": "<p>高性能的DataFrame merge函数</p>\n<p>这是rust_pyfunc.fast_merge的DataFrame封装版本，可以直接传入DataFrame\n并返回标准的DataFrame结果。</p>",
    "params": [
      "left",
      "right",
      "on",
      "left_on",
      "right_on",
      "how"
    ]
  },
  {
    "name": "fast_merge_df",
    "description": "<p>高性能的DataFrame merge函数</p>\n<p>这是rust_pyfunc.fast_merge的DataFrame封装版本，可以直接传入DataFrame\n并返回标准的DataFrame结果。</p>",
    "params": [
      "left",
      "right",
      "on",
      "left_on",
      "right_on",
      "how"
    ]
  },
  {
    "name": "fast_merge_mixed",
    "description": "<p>高性能merge函数，支持字符串和数值类型的连接键</p>",
    "params": []
  },
  {
    "name": "fast_outer_join_df",
    "description": "<p>快速外连接的便捷函数</p>",
    "params": []
  },
  {
    "name": "fast_right_join_df",
    "description": "<p>快速右连接的便捷函数</p>",
    "params": []
  },
  {
    "name": "find_follow_volume_sum_same_price",
    "description": "<p>计算每一行在其后time_window秒内具有相同volume（及可选相同price）的行的volume总和。</p>",
    "params": [
      "times",
      "prices",
      "volumes",
      "time_window",
      "check_price",
      "filter_frequent_volumes"
    ]
  },
  {
    "name": "find_follow_volume_sum_same_price_and_flag",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "find_half_energy_time",
    "description": "<p>计算每个时间点价格达到时间窗口内最终能量一半所需的时间。</p>\n<p>该函数首先计算时间窗口结束时的能量（价格变动的绝对值比率），\n然后计算第一次达到该能量一半所需的时间。</p>\n<h1>参数说明</h1>\n<ul>\n<li><code>times</code> - 时间戳数组（单位：秒）</li>\n<li><code>prices</code> - 价格数组</li>\n<li><code>time_window</code> - 时间窗口大小（单位：秒），默认为5.0</li>\n</ul>\n<h1>返回值</h1>\n<p>浮点数数组，表示每个时间点达到最终能量一半所需的时间（秒）。\n如果在时间窗口内未达到一半能量，则返回time_window值。\n如果最终能量为0，则返回0。</p>\n<h1>特殊情况处理</h1>\n<ul>\n<li>当价格为NaN或Inf时，对应结果为NaN</li>\n<li>当最终能量为0时，结果为0</li>\n<li>当时间窗口内无法计算出最终能量时，结果为time_window</li>\n</ul>\n<h1>性能</h1>\n<p>该函数使用并行处理加速计算，在大规模数据集上比等效的Python实现快约20-100倍。</p>\n<h1>示例</h1>\n<p>```python\nimport pandas as pd\nimport numpy as np\nfrom rust_pyfunc import find_half_energy_time</p>\n<h1>创建示例DataFrame</h1>\n<p>df = pd.DataFrame({\n    'exchtime': [1.0, 1.1, 1.2, 1.3, 1.4],\n    'price': [10.0, 10.2, 10.5, 10.3, 10.1]\n})</p>\n<h1>计算达到一半能量所需时间</h1>\n<p>df['half_energy_time'] = find_half_energy_time(\n    df['exchtime'].values,\n    df['price'].values,\n    time_window=5.0\n)\nprint(df)\n```</p>",
    "params": []
  },
  {
    "name": "find_half_extreme_time",
    "description": "<p>计算每一行在其后指定时间窗口内的价格变动能量，并找出首次达到最终能量一半时所需的时间。</p>",
    "params": [
      "times",
      "prices",
      "time_window"
    ]
  },
  {
    "name": "find_local_peaks_within_window",
    "description": "<p>查找时间序列中价格在指定时间窗口内为局部最大值的点。</p>",
    "params": [
      "times",
      "prices",
      "window"
    ]
  },
  {
    "name": "find_max_range_product",
    "description": "<p>在数组中找到一对索引(x, y)，使得min(arr[x], arr[y]) * |x-y|的值最大。\n这个函数可以用来找到数组中距离最远的两个元素，同时考虑它们的最小值。</p>",
    "params": [
      "arr"
    ]
  },
  {
    "name": "gp_correlation_dimension",
    "description": "<p>可选参数入口：可提供自定义选项</p>",
    "params": []
  },
  {
    "name": "gp_correlation_dimension_auto",
    "description": "<p>零参数入口：只需传入序列，所有参数自动确定</p>",
    "params": []
  },
  {
    "name": "gp_create_default_options",
    "description": "<p>为 Python 导出的辅助函数</p>",
    "params": []
  },
  {
    "name": "gp_create_options",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "hmm_trend_prediction",
    "description": "<p>主要的HMM趋势预测函数</p>",
    "params": []
  },
  {
    "name": "identify_segments",
    "description": "<p>识别数组中的连续相等值段，并为每个段分配唯一标识符。\n每个连续相等的值构成一个段，第一个段标识符为1，第二个为2，以此类推。</p>",
    "params": [
      "arr"
    ]
  },
  {
    "name": "jaccard_similarity",
    "description": "<p>计算两个句子之间的Jaccard相似度。\nJaccard相似度是两个集合交集大小除以并集大小，用于衡量两个句子的相似程度。\n这里将每个句子视为单词集合，忽略单词出现的顺序和频率。</p>",
    "params": [
      "sentence1",
      "sentence2"
    ]
  },
  {
    "name": "local_correlation",
    "description": "<p>计算价格序列的局部相关性分析</p>\n<p>对于每个价格点，向前取x个值作为局部序列，然后分别向前和向后搜索，\n找到与当前局部序列相关性最大和最小的位置，并计算间隔行数和volume总和。</p>",
    "params": [
      "prices",
      "volumes",
      "window_size"
    ]
  },
  {
    "name": "lz_complexity",
    "description": "<p>LZ76增量分解复杂度计算</p>\n<p>参数:\n- seq: 输入序列，可以是1D numpy数组\n- quantiles: 分位数列表，用于连续变量离散化，None表示序列已经是离散的\n- normalize: 是否归一化结果</p>\n<p>返回:\n- LZ复杂度值</p>",
    "params": []
  },
  {
    "name": "lz_complexity_detailed",
    "description": "<p>LZ76增量分解复杂度详细分析计算</p>\n<p>参数:\n- seq: 输入序列，可以是1D numpy数组\n- quantiles: 分位数列表，用于连续变量离散化，None表示序列已经是离散的\n- normalize: 是否归一化结果</p>\n<p>返回:\n- 包含详细统计信息的字典</p>",
    "params": []
  },
  {
    "name": "mark_follow_groups",
    "description": "<p>标记每一行在其后0.1秒内具有相同price和volume的行组。\n对于同一个时间窗口内的相同交易组，标记相同的组号。\n组号从1开始递增，每遇到一个新的交易组就分配一个新的组号。</p>",
    "params": [
      "times",
      "prices",
      "volumes",
      "time_window"
    ]
  },
  {
    "name": "mark_follow_groups_with_flag",
    "description": "<p>标记每一行在其后time_window秒内具有相同flag、price和volume的行组。\n对于同一个时间窗口内的相同交易组，标记相同的组号。\n组号从1开始递增，每遇到一个新的交易组就分配一个新的组号。</p>",
    "params": [
      "times",
      "prices",
      "volumes",
      "flags",
      "time_window"
    ]
  },
  {
    "name": "matrix_eigenvalue_analysis",
    "description": "<p>计算多列数据的差值矩阵特征值</p>\n<p>对输入的237行×n列矩阵，对每一列进行以下操作：\n1. 构建237×237的差值矩阵，其中M[i,j] = col[i] - col[j]\n2. 计算该矩阵的所有特征值\n3. 按特征值绝对值从大到小排序</p>\n<p>此函数针对高性能计算进行了优化：\n- 使用并行处理处理不同列（最多10个核心）\n- 利用差值矩阵的对称性质优化计算\n- 使用高效的线性代数库nalgebra进行特征值分解</p>",
    "params": [
      "matrix"
    ]
  },
  {
    "name": "matrix_eigenvalue_analysis_modified",
    "description": "<p>计算多列数据的修改差值矩阵特征值（高性能版本）</p>\n<p>对输入的m行×n列矩阵，对每一列进行以下操作：\n1. 构建m×m的修改差值矩阵：\n   - 上三角: M[i,j] = col[i] - col[j] (i &lt; j)\n   - 对角线: M[i,i] = 0\n   - 下三角: M[i,j] = |col[i] - col[j]| (i &gt; j)\n2. 计算该矩阵的所有特征值\n3. 按特征值绝对值从大到小排序</p>\n<p>优化策略：\n- 高度并行化（最多10个核心）\n- 内存预分配和重用\n- SIMD优化的矩阵运算\n- 缓存友好的数据访问模式</p>",
    "params": [
      "matrix"
    ]
  },
  {
    "name": "matrix_eigenvalue_analysis_modified_ultra",
    "description": "<p>计算多列数据的修改差值矩阵特征值（超级优化版本）</p>\n<p>这个版本包含了所有可能的性能优化：\n- 预分配内存池\n- 批量处理\n- 缓存优化的数据结构\n- 更高效的特征值算法\n- 1秒超时机制，防止卡死</p>",
    "params": [
      "matrix",
      "print_stats"
    ]
  },
  {
    "name": "matrix_eigenvalue_analysis_optimized",
    "description": "<p>计算多列数据的差值矩阵特征值（优化版本）</p>\n<p>这是一个针对大规模计算优化的版本，使用了更高效的算法：\n1. 利用差值矩阵的反对称性质减少计算量\n2. 使用更高效的内存布局\n3. 优化的并行策略</p>",
    "params": [
      "matrix"
    ]
  },
  {
    "name": "max_range_loop",
    "description": "<p>计算序列中每个位置结尾的最长连续子序列长度，其中子序列的最大值在该位置。</p>",
    "params": [
      "s",
      "allow_equal"
    ]
  },
  {
    "name": "min_range_loop",
    "description": "<p>计算序列中每个位置结尾的最长连续子序列长度，其中子序列的最小值在该位置。</p>",
    "params": [
      "s",
      "allow_equal"
    ]
  },
  {
    "name": "min_word_edit_distance",
    "description": "<p>计算将一个句子转换为另一个句子所需的最少单词操作次数（添加/删除）。</p>\n<h1>参数</h1>\n<ul>\n<li><code>str1</code> - 源句子</li>\n<li><code>str2</code> - 目标句子</li>\n</ul>\n<h1>示例</h1>\n<p>```python\nfrom rust_pyfunc import min_word_edit_distance</p>\n<h1>示例1：添加一个单词</h1>\n<p>da = \"We expect demand to increase\"\ndb = \"We expect worldwide demand to increase\"\nprint(min_word_edit_distance(da, db))  # 输出: 1 (添加 \"worldwide\")</p>\n<h1>示例2：多次修改</h1>\n<p>dc = \"We expect weakness in sales\"\nprint(min_word_edit_distance(da, dc))  # 输出: 6 (删除3个单词，添加3个单词)\n```</p>",
    "params": []
  },
  {
    "name": "mutual_information_2d_knn",
    "description": "<p>Calculate mutual information for corresponding rows of two 2D arrays\nusing KSG (Kraskov-Stögbauer-Grassberger) method 1 with consistent Euclidean distance.\nBoth joint and marginal neighbor counting use the same Euclidean distance metric.</p>",
    "params": []
  },
  {
    "name": "mutual_information_2d_knn_chebyshev",
    "description": "<p>Calculate mutual information for corresponding rows using Chebyshev distance</p>",
    "params": []
  },
  {
    "name": "mutual_information_2d_knn_final",
    "description": "<p>Calculate mutual information for corresponding rows of two 2D arrays\nusing corrected KSG method with negative value truncation.</p>\n<p>此函数是mutual_information_2d_knn的最终修复版本，解决了负数互信息的问题。</p>\n<p>修复原理：\nKSG估计器在弱相关情况下可能产生负值估计，这是已知的有限样本偏差现象。\n根据信息论理论，互信息I(X;Y) ≥ 0永远成立，因此我们将负值截断为0。\n这是处理KSG估计器负值问题的标准做法。</p>\n<p>算法特点：\n- 使用KSG方法1进行互信息估计\n- 采用Chebyshev距离确定k近邻\n- 实施负值截断确保理论一致性\n- 保持高性能的Rust实现</p>",
    "params": []
  },
  {
    "name": "mutual_information_2d_knn_fixed",
    "description": "<p>Calculate mutual information for corresponding rows of two 2D arrays\nusing corrected KSG (Kraskov-Stögbauer-Grassberger) method.\nThis fixes the negative values issue by using proper 1D counting.</p>",
    "params": []
  },
  {
    "name": "mutual_information_knn",
    "description": "<p>Calculate mutual information using KSG (Kraskov-Stögbauer-Grassberger) method 1\nUses Euclidean distance for k-nearest neighbor search</p>",
    "params": []
  },
  {
    "name": "mutual_information_knn_chebyshev",
    "description": "<p>Calculate mutual information using KSG method 2 (Chebyshev distance)</p>",
    "params": []
  },
  {
    "name": "ols",
    "description": "<p>普通最小二乘(OLS)回归。\n用于拟合线性回归模型 y = Xβ + ε，其中β是要估计的回归系数。</p>",
    "params": [
      "x",
      "y",
      "calculate_r2"
    ]
  },
  {
    "name": "ols_predict",
    "description": "<p>使用已有数据和响应变量，对新的数据点进行OLS线性回归预测。</p>",
    "params": [
      "x",
      "y",
      "x_pred"
    ]
  },
  {
    "name": "ols_residuals",
    "description": "<p>计算普通最小二乘(OLS)回归的残差序列。\n残差表示实际观测值与模型预测值之间的差异: ε = y - Xβ。</p>",
    "params": [
      "x",
      "y"
    ]
  },
  {
    "name": "order_contamination",
    "description": "<p>优化版订单浸染函数 - 高性能单线程版本</p>\n<h1>参数</h1>\n<ul>\n<li>exchtime: 成交时间数组（纳秒）</li>\n<li>order: 订单编号数组</li>\n<li>volume: 成交量数组  </li>\n<li>top_percentile: 大单百分比阈值 (1-100)，表示前x%，默认10表示前10%</li>\n<li>time_window_seconds: 时间窗口（秒），默认1秒</li>\n</ul>\n<h1>返回</h1>\n<p>浸染后的订单编号数组</p>",
    "params": []
  },
  {
    "name": "order_contamination_bilateral",
    "description": "<p>双边订单浸染函数 - 分别处理买单和卖单的浸染</p>\n<h1>参数</h1>\n<ul>\n<li>exchtime: 成交时间数组（纳秒）</li>\n<li>bid_order: 买单编号数组</li>\n<li>ask_order: 卖单编号数组  </li>\n<li>volume: 成交量数组</li>\n<li>top_percentile: 大单百分比阈值 (1-100)，表示前x%，默认10表示前10%</li>\n<li>time_window_seconds: 时间窗口（秒），默认1秒</li>\n</ul>\n<h1>返回</h1>\n<p>(浸染后的买单编号数组, 浸染后的卖单编号数组)</p>",
    "params": []
  },
  {
    "name": "order_contamination_parallel",
    "description": "<p>并行版本的订单浸染函数（使用5核心，适用于大数据量）</p>",
    "params": []
  },
  {
    "name": "order_neighborhood_analysis",
    "description": "<p>超级高速订单邻域分析函数 - 为13万数据优化</p>\n<p>激进优化策略：\n1. 预计算邻域索引表\n2. 批量SIMD计算\n3. 内存预分配避免动态分配\n4. 分层并行处理\n5. 零拷贝数据传递</p>",
    "params": []
  },
  {
    "name": "pandas_series_rank",
    "description": "<p>计算pandas Series的排名 (单线程版本)</p>\n<h1>Arguments</h1>\n<ul>\n<li><code>data</code> - 输入的一维数组数据</li>\n<li><code>method</code> - 排名方法: \"average\", \"min\", \"max\", \"first\", \"dense\"</li>\n<li><code>ascending</code> - 是否升序排列</li>\n<li><code>na_option</code> - NaN处理方式: \"keep\", \"top\", \"bottom\"</li>\n</ul>\n<h1>Returns</h1>\n<ul>\n<li>排名结果的一维数组</li>\n</ul>",
    "params": []
  },
  {
    "name": "price_volume_orderbook_correlation",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "query_backup",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "query_backup_columns_range_with_filter",
    "description": "<p>查询备份文件中的指定列范围，支持过滤</p>\n<p>参数:\n- backup_file: 备份文件路径\n- column_start: 开始列索引（包含）\n- column_end: 结束列索引（包含）\n- dates: 可选的日期过滤列表\n- codes: 可选的代码过滤列表</p>\n<p>返回:\n包含numpy数组的字典: {\"date\": 日期数组, \"code\": 代码数组, \"factors\": 指定列范围的因子值数组}</p>",
    "params": []
  },
  {
    "name": "query_backup_factor_only",
    "description": "<p>查询备份文件中的指定列因子值（纯因子值数组）</p>\n<p>参数:\n- backup_file: 备份文件路径\n- column_index: 要读取的因子列索引（0表示第一列因子值）</p>\n<p>返回:\n只包含因子值的numpy数组</p>",
    "params": []
  },
  {
    "name": "query_backup_factor_only_ultra_fast",
    "description": "<p>超高速查询备份文件中的指定列因子值</p>\n<p>参数:\n- backup_file: 备份文件路径\n- column_index: 要读取的因子列索引（0表示第一列因子值）</p>\n<p>返回:\n只包含因子值的numpy数组</p>",
    "params": []
  },
  {
    "name": "query_backup_factor_only_with_filter",
    "description": "<p>查询备份文件中的指定列因子值（纯因子值数组），支持过滤</p>\n<p>参数:\n- backup_file: 备份文件路径\n- column_index: 要读取的因子列索引（0表示第一列因子值）\n- dates: 可选的日期过滤列表\n- codes: 可选的代码过滤列表</p>\n<p>返回:\n只包含因子值的numpy数组</p>",
    "params": []
  },
  {
    "name": "query_backup_fast",
    "description": "<p>高速并行备份查询函数，专门优化大文件读取</p>",
    "params": []
  },
  {
    "name": "query_backup_single_column",
    "description": "<p>查询备份文件中的指定列</p>\n<p>参数:\n- backup_file: 备份文件路径\n- column_index: 要读取的因子列索引（0表示第一列因子值）</p>\n<p>返回:\n包含三个numpy数组的字典: {\"date\": 日期数组, \"code\": 代码数组, \"factor\": 指定列的因子值数组}</p>",
    "params": []
  },
  {
    "name": "query_backup_single_column_with_filter",
    "description": "<p>查询备份文件中的指定列，支持过滤</p>\n<p>参数:\n- backup_file: 备份文件路径\n- column_index: 要读取的因子列索引（0表示第一列因子值）\n- dates: 可选的日期过滤列表\n- codes: 可选的代码过滤列表</p>\n<p>返回:\n包含三个numpy数组的字典: {\"date\": 日期数组, \"code\": 代码数组, \"factor\": 指定列的因子值数组}</p>",
    "params": []
  },
  {
    "name": "rank_axis0_df",
    "description": "<p>高性能的DataFrame rank函数，支持axis=0（沿列方向排名）</p>\n<p>通过转置实现沿列方向的排名，同样具有高性能优势。</p>",
    "params": [
      "df",
      "method",
      "ascending",
      "na_option"
    ]
  },
  {
    "name": "rank_axis0_df",
    "description": "<p>高性能的DataFrame rank函数，支持axis=0（沿列方向排名）</p>\n<p>通过转置实现沿列方向的排名，同样具有高性能优势。</p>",
    "params": [
      "df",
      "method",
      "ascending",
      "na_option"
    ]
  },
  {
    "name": "rank_axis1",
    "description": "<p>高性能的DataFrame rank函数，支持axis=1（沿行方向排名）\n相比pandas的rank函数能显著提升性能</p>",
    "params": [
      "data",
      "method",
      "ascending",
      "na_option"
    ]
  },
  {
    "name": "rank_axis1_df",
    "description": "<p>高性能的DataFrame rank函数，支持axis=1（沿行方向排名）</p>\n<p>这是rust_pyfunc.rank_axis1的DataFrame封装版本，可以直接传入DataFrame\n并返回保持原有索引和列名的DataFrame结果。</p>",
    "params": [
      "df",
      "method",
      "ascending",
      "na_option"
    ]
  },
  {
    "name": "rank_axis1_df",
    "description": "<p>高性能的DataFrame rank函数，支持axis=1（沿行方向排名）</p>\n<p>这是rust_pyfunc.rank_axis1的DataFrame封装版本，可以直接传入DataFrame\n并返回保持原有索引和列名的DataFrame结果。</p>",
    "params": [
      "df",
      "method",
      "ascending",
      "na_option"
    ]
  },
  {
    "name": "rank_axis1_df",
    "description": "<p>高性能的DataFrame rank函数，支持axis=1（沿行方向排名）</p>\n<p>这是rust_pyfunc.rank_axis1的DataFrame封装版本，可以直接传入DataFrame\n并返回保持原有索引和列名的DataFrame结果。</p>",
    "params": [
      "df",
      "method",
      "ascending",
      "na_option"
    ]
  },
  {
    "name": "rolling_correlation_mean",
    "description": "<p>滚动窗口计算相关性矩阵均值</p>\n<p>对于输入数据的每一行，计算其过去window_size行的相关性矩阵，\n然后计算该相关性矩阵中所有值的均值。</p>",
    "params": [
      "data",
      "window_size",
      "min_periods",
      "max_workers"
    ]
  },
  {
    "name": "rolling_correlation_skew",
    "description": "<p>滚动窗口计算相关性矩阵偏度</p>\n<p>对于输入数据的每一行，计算其过去window_size行的相关性矩阵，\n然后计算该相关性矩阵中所有值的偏度（skewness）。\n偏度衡量相关性分布的不对称性：\n- 偏度 &gt; 0：右偏（正偏），大部分相关性值较小，少数值较大\n- 偏度 &lt; 0：左偏（负偏），大部分相关性值较大，少数值较小\n- 偏度 ≈ 0：接近对称分布</p>",
    "params": [
      "data",
      "window_size",
      "min_periods",
      "max_workers"
    ]
  },
  {
    "name": "rolling_cv",
    "description": "<p>计算价格序列的滚动变异系数(CV)。</p>\n<p>对于位置i，从数据范围[i-lookback+1, i]中每隔interval个点取样，\n然后计算相邻样本之间的对数收益率（后面的价格除以前面的价格的对数），\n最后计算这些收益率的变异系数（标准差除以均值）。</p>",
    "params": [
      "values",
      "lookback",
      "interval",
      "min_periods"
    ]
  },
  {
    "name": "rolling_dtw_distance",
    "description": "<p>计算每个大单与其临近小单之间的时间间隔均值。</p>",
    "params": [
      "volumes",
      "exchtimes",
      "large_quantile",
      "small_quantile",
      "near_number",
      "exclude_same_time"
    ]
  },
  {
    "name": "rolling_lagged_regression",
    "description": "<p>滞后自回归分析函数</p>\n<p>参数:\n- series: 一维时间序列数据\n- past_periods: 过去观察期数\n- future_periods: 预测期数，必须 &lt;= past_periods</p>\n<p>返回:\n- 二维数组 (n, 2*x)，其中 x = past_periods - future_periods + 1\n- 每行包含 [r_lag1_past, r_lag2_past, ..., r_lagx_past, r_lag1_future, r_lag2_future, ..., r_lagx_future]</p>",
    "params": []
  },
  {
    "name": "rolling_lagged_regression_ridge",
    "description": "<p>Ridge回归版本的滞后自回归分析函数</p>\n<p>参数:\n- series: 一维时间序列数据\n- past_periods: 过去观察期数\n- future_periods: 预测期数，必须 &lt;= past_periods\n- alpha: Ridge正则化参数，默认使用自适应选择</p>\n<p>返回:\n- 二维数组 (n, 2*x)，其中 x = past_periods - future_periods + 1\n- 每行包含 [r_lag1_past, r_lag2_past, ..., r_lagx_past, r_lag1_future, r_lag2_future, ..., r_lagx_future]</p>",
    "params": []
  },
  {
    "name": "rolling_lagged_regression_ridge_fast",
    "description": "<p>高性能Ridge回归版本的滞后自回归分析函数</p>\n<p>参数:\n- series: 一维时间序列数据\n- past_periods: 过去观察期数\n- future_periods: 预测期数，必须 &lt;= past_periods\n- alpha: Ridge正则化参数，默认使用自适应选择</p>\n<p>返回:\n- 二维数组 (n, 2*x)，其中 x = past_periods - future_periods + 1\n- 每行包含 [r_lag1_past, r_lag2_past, ..., r_lagx_past, r_lag1_future, r_lag2_future, ..., r_lagx_future]</p>\n<p>优化特性:\n- 使用faer库实现5-17倍矩阵运算性能提升\n- 内存池和缓冲区重用减少分配开销\n- alpha参数缓存机制减少重复计算</p>",
    "params": []
  },
  {
    "name": "rolling_lagged_regression_ridge_incremental",
    "description": "<p>增量更新版本的滞后自回归分析</p>\n<p>核心优化：\n1. 维护X'X和X'y矩阵的增量更新，避免重复计算\n2. 利用滑动窗口的重叠特性，每次只计算差量\n3. 预期性能提升30-40%</p>",
    "params": []
  },
  {
    "name": "rolling_lagged_regression_ridge_simd",
    "description": "<p>SIMD优化版本的主函数</p>",
    "params": []
  },
  {
    "name": "rolling_qcv",
    "description": "<p>计算价格序列的滚动四分位变异系数(QCV)。</p>\n<p>对于位置i，从数据范围[i-lookback+1, i]中每隔interval个点取样，\n然后计算相邻样本之间的对数收益率（后面的价格除以前面的价格的对数），\n最后计算这些收益率的四分位变异系数（四分位间距除以中位数的绝对值）。\n这种方法对异常值和均值接近零的情况更加稳健。</p>",
    "params": [
      "values",
      "lookback",
      "interval",
      "min_periods"
    ]
  },
  {
    "name": "rolling_volatility",
    "description": "<p>计算价格序列的滚动波动率。</p>\n<p>对于位置i，从数据范围[i-lookback+1, i]中每隔interval个点取样，\n然后计算相邻样本之间的对数收益率（后面的价格除以前面的价格的对数），\n最后计算这些收益率的标准差作为波动率。</p>",
    "params": [
      "prices",
      "lookback",
      "interval",
      "min_periods"
    ]
  },
  {
    "name": "rolling_window_core_feature",
    "description": "<p>滚动窗口核心特征提取</p>\n<p>对输入序列进行滚动窗口分析，识别每个窗口中最重要的特征位置（核心特征）\n和最不重要的特征位置。通过计算窗口间的相关性并分析mask效应来确定特征重要性。</p>\n<p>算法原理：\n1. 对每个滚动窗口，计算其与所有其他窗口的相关系数（基准相关性）\n2. 依次将窗口内每个位置设为NaN，重新计算相关系数\n3. 相关性变化最小的位置为最重要特征（核心代表性）\n4. 相关性变化最大的位置为最不重要特征</p>",
    "params": [
      "values",
      "window_size"
    ]
  },
  {
    "name": "rolling_window_core_feature_optimized",
    "description": "<p>优化版滚动窗口核心特征提取</p>\n<p>针对性能优化的版本，使用以下优化策略：\n1. 增量相关性计算：避免重复计算统计量\n2. 预计算缓存：缓存窗口间的相关性矩阵\n3. 内存优化：重用缓冲区，减少内存分配\n4. 向量化操作：使用SIMD友好的计算模式</p>",
    "params": [
      "values",
      "window_size"
    ]
  },
  {
    "name": "rolling_window_core_feature_simd",
    "description": "<p>SIMD优化版滚动窗口核心特征提取</p>\n<p>使用显式SIMD指令和智能缓存策略优化性能：\n1. SIMD向量化统计量计算\n2. LRU缓存避免重复相关性计算\n3. 批量内存访问优化\n4. 数值计算热点优化</p>",
    "params": [
      "values",
      "window_size"
    ]
  },
  {
    "name": "rolling_window_core_feature_ultra",
    "description": "<p>超级轻量级优化版滚动窗口核心特征提取</p>\n<p>基于性能测试结果，专注于最有效的优化：\n1. 极致的内联优化\n2. 最小化内存分配\n3. CPU缓存友好的数据访问模式\n4. 编译器友好的代码结构</p>\n<p>去掉所有复杂缓存机制，专注于算法核心优化</p>",
    "params": [
      "values",
      "window_size"
    ]
  },
  {
    "name": "rolling_window_stat",
    "description": "<p>计算时间序列在指定时间窗口内向后滚动的统计量。\n对于每个时间点，计算该点之后指定时间窗口内所有数据的指定统计量。</p>",
    "params": [
      "times",
      "values",
      "window",
      "stat_type"
    ]
  },
  {
    "name": "rolling_window_stat_backward",
    "description": "<p>计算时间序列在指定时间窗口内向前滚动的统计量。\n对于每个时间点，计算该点之前指定时间窗口内所有数据的指定统计量。</p>",
    "params": [
      "times",
      "values",
      "window",
      "stat_type"
    ]
  },
  {
    "name": "run_pools_queue",
    "description": "<p>无文档</p>",
    "params": []
  },
  {
    "name": "run_pools_simple",
    "description": "<p>极简版并行计算函数 - 只执行不返回</p>",
    "params": []
  },
  {
    "name": "segment_and_correlate",
    "description": "<p>序列分段和相关系数计算函数</p>\n<p>输入两个等长的序列，根据大小关系进行分段，然后计算每段内的相关系数</p>",
    "params": [
      "a",
      "b",
      "min_length"
    ]
  },
  {
    "name": "sum_as_string",
    "description": "<p>Formats the sum of two numbers as string.</p>",
    "params": []
  },
  {
    "name": "super_dtw_distance",
    "description": "<p>超级优化版DTW距离函数，使用以下高级技术提升性能：\n1. 内存预分配 - 减少运行时内存分配\n2. 更精细的内存访问优化 - 提高缓存命中率\n3. 基于启发式的跳过技术 - 避免不必要的计算\n4. 提前退出策略 - 当部分结果已超过最优值时提前终止\n5. 更稀疏的超时检查 - 减少检查开销</p>\n<p>```python\nimport numpy as np\nfrom rust_pyfunc import super_dtw_distance, fast_dtw_distance, dtw_distance</p>\n<h1>创建两个时间序列</h1>\n<p>s1 = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\ns2 = np.array([1.1, 2.1, 3.1, 4.1, 5.1])</p>\n<h1>比较三种实现的结果和性能</h1>\n<p>import time</p>\n<p>start = time.time()\nresult1 = dtw_distance(s1, s2)\ntime1 = time.time() - start</p>\n<p>start = time.time()\nresult2 = fast_dtw_distance(s1, s2)\ntime2 = time.time() - start</p>\n<p>start = time.time()\nresult3 = super_dtw_distance(s1, s2)\ntime3 = time.time() - start</p>\n<p>print(f\"标准DTW距离: {result1:.6f}, 耗时: {time1:.6f}秒\")\nprint(f\"快速DTW距离: {result2:.6f}, 耗时: {time2:.6f}秒\")\nprint(f\"超级DTW距离: {result3:.6f}, 耗时: {time3:.6f}秒\")\nprint(f\"fast加速比: {time1/time2:.2f}倍\")\nprint(f\"super加速比: {time1/time3:.2f}倍\")\n```</p>",
    "params": []
  },
  {
    "name": "super_find_half_extreme_time",
    "description": "<p>计算半极端时间的超级优化版本</p>\n<p>与fast_find_half_extreme_time相比，该函数引入了以下额外优化：\n1. SIMD加速 - 利用向量化操作加速计算\n2. 高级缓存优化 - 通过预计算和数据布局进一步提高缓存命中率\n3. 直接内存操作 - 减少边界检查和间接访问\n4. 预先筛选 - 先过滤掉不可能的时间范围\n5. 多线程并行 - 在可能的情况下使用并行计算</p>",
    "params": []
  },
  {
    "name": "test_function",
    "description": "<p>简单测试函数，确保模块导出正常工作</p>",
    "params": []
  },
  {
    "name": "trade_peak_analysis",
    "description": "<p>交易高峰模式分析函数</p>\n<p>该函数用于分析交易数据中的高峰模式，包括：\n1. 识别成交量的局部高峰(根据top_tier1百分比)\n2. 在每个高峰的时间窗口内识别小峰(根据top_tier2百分比)\n3. 计算17个统计指标来描述高峰-小峰的模式特征</p>",
    "params": [
      "exchtime",
      "volume",
      "flag",
      "top_tier1",
      "top_tier2",
      "time_window",
      "flag_different",
      "with_forth"
    ]
  },
  {
    "name": "transfer_entropy",
    "description": "<p>计算从序列x到序列y的转移熵（Transfer Entropy）。\n转移熵衡量了一个时间序列对另一个时间序列的影响程度，是一种非线性的因果关系度量。\n具体来说，它测量了在已知x的过去k个状态的情况下，对y的当前状态预测能力的提升程度。</p>",
    "params": [
      "x_",
      "y_",
      "k",
      "c"
    ]
  },
  {
    "name": "transfer_entropy_safe",
    "description": "<p>计算从序列 x 到序列 y 的转移熵（安全版本，可处理 NaN 值）</p>\n<p>该函数计算从时间序列 x 到时间序列 y 的转移熵，用于量化 x 对 y 的因果影响。\n与原版 transfer_entropy 不同，此版本能够安全处理包含 NaN 值的数据。</p>\n<h1>Arguments</h1>\n<ul>\n<li><code>x_</code> - 源时间序列，可以包含 NaN 值</li>\n<li><code>y_</code> - 目标时间序列，可以包含 NaN 值  </li>\n<li><code>k</code> - 时间延迟参数</li>\n<li><code>c</code> - 离散化的分箱数量</li>\n</ul>\n<h1>Returns</h1>\n<p>转移熵值，如果数据不足或全为 NaN 则返回 0.0</p>\n<h1>Examples</h1>\n<p>```python\nimport numpy as np\nimport rust_pyfunc</p>\n<h1>创建包含 NaN 的数据</h1>\n<p>x = [1.0, 2.0, np.nan, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\ny = [2.0, 3.0, 4.0, 5.0, np.nan, 7.0, 8.0, 9.0, 10.0, 11.0]</p>\n<h1>安全计算转移熵（不会 panic）</h1>\n<p>te = rust_pyfunc.transfer_entropy_safe(x, y, k=1, c=3)\nprint(f\"转移熵: {te}\")\n```</p>",
    "params": []
  },
  {
    "name": "trend",
    "description": "<p>计算输入数组与自然数序列(1, 2, ..., n)之间的皮尔逊相关系数。\n这个函数可以用来判断一个序列的趋势性，如果返回值接近1表示强上升趋势，接近-1表示强下降趋势。</p>",
    "params": [
      "arr"
    ]
  },
  {
    "name": "trend_2d",
    "description": "<p>计算二维数组各行或各列的趋势性</p>",
    "params": [
      "arr",
      "axis"
    ]
  },
  {
    "name": "trend_fast",
    "description": "<p>这是trend函数的高性能版本，专门用于处理numpy.ndarray类型的float64数组。\n使用了显式的SIMD指令和缓存优化处理，比普通版本更快。</p>",
    "params": [
      "arr"
    ]
  },
  {
    "name": "vector_similarity_matrices",
    "description": "<p>超级优化的向量相似度矩阵计算（零拷贝 + SIMD + 对称性）</p>\n<p>主要优化技术：\n- 零拷贝输入：使用PyReadonlyArray1避免Python到Rust的数据拷贝\n- SIMD向量化：使用AVX2指令集并行计算4个元素\n- 对称性优化：只计算上三角矩阵，减少一半计算量\n- 直接内存操作：直接写入numpy数组内存，避免中间分配\n- 缓存友好：优化内存访问模式，提高缓存命中率</p>",
    "params": []
  },
  {
    "name": "vectorize_sentences",
    "description": "<p>将两个句子转换为词频向量。\n生成的向量长度相同，等于两个句子中不同单词的总数。\n向量中的每个位置对应一个单词，值表示该单词在句子中出现的次数。</p>",
    "params": [
      "sentence1",
      "sentence2"
    ]
  },
  {
    "name": "vectorize_sentences_list",
    "description": "<p>将多个句子转换为词频向量列表。\n生成的所有向量长度相同，等于所有句子中不同单词的总数。\n每个向量中的每个位置对应一个单词，值表示该单词在对应句子中出现的次数。</p>",
    "params": [
      "sentences"
    ]
  }
]